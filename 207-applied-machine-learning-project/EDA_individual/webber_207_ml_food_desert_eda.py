# -*- coding: utf-8 -*-
"""Webber 207 ML: Food Desert EDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jG9PbaTQ95_n1mCEMTwM3blotJchA1YU
"""



"""## EDA ##"""

# %pip install --quiet geopandas

# import libraries
import re
import os
import json
import pandas as pd
import numpy as np
import seaborn as sns
import geopandas as gpd
import matplotlib.pyplot as plt
import tempfile
import urllib.request
import zipfile

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

file_path = r"/content/drive/MyDrive/207 Machine Learning: Final Project/Data/regional_combined_centroids.csv"
atlas_data = pd.read_csv(file_path)
atlas_data.head()

atlas_data.shape # look at shape of data

atlas_data.info() # inspect columns

import json

rename_path = r"/content/drive/MyDrive/207 Machine Learning: Final Project/Data/rename.json"

with open(rename_path, 'r') as f:
    rename = json.load(f)

rename_dict = {}
for col in atlas_data.columns:
    if col in rename.keys():
        rename_dict[col] = rename[col]['simplifiedName']

atlas_data.rename(columns=rename_dict, inplace=True)

atlas_data

"""# Step 1: Look at how food desert vs non-food desert is split in data:"""

#distribution overall
atlas_data["LILA_Urban1_Rural10"].value_counts()
atlas_data["LILA_Urban1_Rural10"].value_counts(normalize=True)

"""note: there is imbalance but it doesnt seem awful?"""

counts = atlas_data["LILA_Urban1_Rural10"].value_counts()

counts.plot(kind='bar', color=["green", "red"])
plt.title("Number of Tracts by Food Desert Status")
plt.xlabel("Food Desert (1 = Yes, 0 = No)")
plt.ylabel("Number of Tracts")
plt.xticks(rotation=0)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

#distribution by state
atlas_data.groupby(["StateName", "LILA_Urban1_Rural10"]).size().unstack(fill_value=0)

grouped = atlas_data.groupby(["StateName", "LILA_Urban1_Rural10"]).size().unstack(fill_value=0)

grouped.plot(kind='bar', stacked=True, color=["green", "red"])
plt.title("Tracts by State and Food Desert Status")
plt.xlabel("State")
plt.ylabel("Number of Tracts")
plt.legend(["Not Food Desert (0)", "Food Desert (1)"])
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()

#proportions by state

state_props = atlas_data.groupby("StateName")["LILA_Urban1_Rural10"].value_counts(normalize=True).unstack()
state_props.columns = ["% Not Food Desert", "% Food Desert"]
state_props = state_props.round(3)
state_props

proportions = grouped.div(grouped.sum(axis=1), axis=0)

proportions.plot(kind='bar', stacked=True, color=["green", "red"])
plt.title("Proportion of Food Desert vs. Non by State")
plt.xlabel("State")
plt.ylabel("Proportion")
plt.legend(["Not Food Desert (0)", "Food Desert (1)"])
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()

state_contribution = atlas_data["StateName"].value_counts(normalize=True).rename("% of Total").round(3)
state_contribution

"""note: Arkansas and Mississippi may not be accurately captured in our development

# Step 2: Check Overall Data Cleanliness
"""

print(atlas_data.isnull().sum().sort_values(ascending=False).to_string())

"""note: doesnt seem to be missing anything important that we'd want to use"""

atlas_data.duplicated().sum()
atlas_data["TractID"].duplicated().sum()

"""note: no duplicates

# Step 3: Do we have images for each tract/row?
"""

!unzip "/content/drive/MyDrive/207 Machine Learning: Final Project/Data/Pictures/Alabama/Alabama.zip" -d "/content/drive/MyDrive/207 Machine Learning: Final Project/Data/Pictures/Alabama"

!ls "/content/drive/MyDrive/207 Machine Learning: Final Project/Data/Pictures/Alabama"

#unzip all the images

import zipfile
import os

base_path = "/content/drive/MyDrive/207 Machine Learning: Final Project/Data/Pictures"


for state_folder in os.listdir(base_path):
    state_path = os.path.join(base_path, state_folder)
    if os.path.isdir(state_path):
        for file in os.listdir(state_path):
            if file.endswith(".zip"):
                zip_path = os.path.join(state_path, file)
                print(f"Unzipping {zip_path}...")
                with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                    zip_ref.extractall(state_path)

import glob

image_dir = "/content/drive/MyDrive/207 Machine Learning: Final Project/Data/Pictures"
image_files = glob.glob(f"{image_dir}/**/*.jpg", recursive=True)

print(f"Total images found: {len(image_files)}")

"""note: this is approx our dataframe shape 7121 vs 7124

# Step 4: Examine where the lat/longs are grouped
"""

plt.figure(figsize=(10, 6))

colors = {0: "green", 1: "red"}
labels = {0: "Not Food Desert", 1: "Food Desert"}

for label_val in [0, 1]:
    subset = atlas_data[atlas_data["LILA_Urban1_Rural10"] == label_val]
    plt.scatter(subset["longitude"], subset["latitude"],
                s=5, c=colors[label_val], label=labels[label_val], alpha=0.5)

plt.xlabel("Longitude")
plt.ylabel("Latitude")
plt.title("Spatial Distribution of Tracts by Food Desert Label")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

note: so it looks like food deserts tend to be clustered together in groups. and in this scatterplot, they are more concentrated in the west
note2: it also looks like food deserts sort of surround cities?

"""# Step 6: Do image labels make sense?"""

from PIL import Image

base_path = "/content/drive/MyDrive/207 Machine Learning: Final Project/Data/Pictures"

# Filter by food desert or not
food_desert = atlas_data[atlas_data["LILA_Urban1_Rural10"] == 1]
non_food_desert = atlas_data[atlas_data["LILA_Urban1_Rural10"] == 0]

def show_examples(df, label, n=3):
    samples = df.sample(n)
    fig, axs = plt.subplots(1, n, figsize=(15, 5))
    fig.suptitle(f"{label} Tracts", fontsize=16)

    for i, (_, row) in enumerate(samples.iterrows()):
        tract = str(row["TractID"])
        label_val = int(row["LILA_Urban1_Rural10"])
        state = row["StateName"] if "StateName" in row else row["StateName"]
        img_name = f"{label_val}_{tract}.jpg"
        img_path = os.path.join(base_path, state, img_name)

        if os.path.exists(img_path):
            img = Image.open(img_path)
            axs[i].imshow(img)
            axs[i].axis('off')
            axs[i].set_title(f"{state} | TractID {tract}")
        else:
            axs[i].text(0.5, 0.5, 'Missing', ha='center', va='center')
            axs[i].axis('off')

    plt.tight_layout()
    plt.show()

# inspect
show_examples(food_desert, "Food Desert")
show_examples(non_food_desert, "Not Food Desert")

"""note: not going to lie....i dont think these all visually check out

# Step 7: Check out Image Sizing
"""

image_root = "/content/drive/MyDrive/207 Machine Learning: Final Project/Data/Pictures"

#get every image
image_paths = []
for root, dirs, files in os.walk(image_root):
    for file in files:
        if file.endswith(".jpg"):
            image_paths.append(os.path.join(root, file))

#create function to get dimensions
def get_dims(file):
    try:
        im = Image.open(file)
        arr = np.array(im)
        #return the height, width, and channels
        return arr.shape
    except:
        return None

# sample
dims = [get_dims(p) for p in image_paths[:500]]
dims = [d for d in dims if d is not None]

# Count dimension frequencies
from collections import Counter
Counter(dims)

"""Next Steps:
-resize images and normalize pixel values (like in the last homework)
"""